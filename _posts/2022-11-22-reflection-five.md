---
layout: post
title:  "Reflection 5"
date:   "2022-11-22" 
categories: jekyll update
---

## Source
["Hermeneutica: Computer-Assisted Interpretation in the Humanities (Chapter 2)"](file:///Users/rohanvalia/Downloads/The_Measured_Words_How_Computers_Analyze_Text-1%20(1).pdf)  

## Reflection

In this writing, the authors Geoffrey Rockwell and Stefan Sinclair present the applications and limitations of computers in analyzing text by dissecting at the fundamental processing and wiring of computers. In doing so, the authors attempt to establish the concept that computers can be used to provide humanists with more efficient methods and features in reading rather than replace humans in the analysis and comprehension of reading. For example, one useful analytical feature offered by computers that the authors refer to is tokenization, which summarizes a text by the most common words that appear by first dissecting the text into smaller sections of text. Through this tokenization and word counting, computers can then create visualizations such as word clouds or distribution graphs, which can allow a humanist to better understand and analyze the key themes of a certain text. Ultimately, through these methods, the authors are able to demonstrate how computers can create adaptive and interpretive models for humanists to become more proficient in their research and analysis. 

One notable idea that the authors present is that features generated by computers, such as word counts and distribution graphs, can often present a trend that can be unrelated or unnoteworthy in regards to the theme and significant of the text. For example, the authors refer to how in the novel Frankenstein, the words "was" and "had" were frequently used, which may not have much indication of the theme of the novel and could instead just be an indication of the writing style or tense of the novel's author. Thus, the authors caution the reader that such tools offered by computers be used in order to enhance reading rather than be used for direct analysis and interpretation. In parallel to this concept, the authors present the important idea that computing can be used to formalize data rather than quantify data. Within this idea, the authors demonstrate that computers are able to formalize analysis by creating models and visualizations, which raises questions and ideas regarding the text that enables the humanist to explore further research and reading.

One question I have for the authors is: What are the negative impacts on humanists, if any, in using computers to synthesize text on the true identity of humanities?

